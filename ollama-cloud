#!/usr/bin/env python3
import os
import sys
import json
import requests
import threading
import itertools
import time

CONFIG_DIR = os.path.expanduser("~/.config/ollama-cloud")
ENV_FILE = os.path.join(CONFIG_DIR, "env")

API_CHAT_URL = "https://ollama.com/api/chat"
API_MODELS_URL = "https://ollama.com/api/tags"


# ------------------------------------------------------------
# API KEY
# ------------------------------------------------------------
def load_api_key():
    if "OLLAMAKEY" in os.environ:
        return os.environ["OLLAMAKEY"]

    if os.path.exists(ENV_FILE):
        with open(ENV_FILE) as f:
            for line in f:
                if line.startswith("OLLAMAKEY="):
                    key = line.split("=", 1)[1].strip()
                    os.environ["OLLAMAKEY"] = key
                    return key

    print("No API key found.")
    key = input("Enter your Ollama API key: ").strip()

    os.makedirs(CONFIG_DIR, exist_ok=True)
    with open(ENV_FILE, "w") as f:
        f.write("OLLAMAKEY=" + key + "\n")

    os.environ["OLLAMAKEY"] = key
    print("API key saved.")
    return key


# ------------------------------------------------------------
# MODELS
# ------------------------------------------------------------
def list_models():
    key = load_api_key()
    headers = {"Authorization": f"Bearer {key}"}
    r = requests.get(API_MODELS_URL, headers=headers)
    r.raise_for_status()
    return r.json().get("models", [])


# ------------------------------------------------------------
# SPINNER
# ------------------------------------------------------------
class Spinner:
    def __init__(self):
        self.running = False
        self.thread = None

    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self._spin, daemon=True)
        self.thread.start()

    def _spin(self):
        for c in itertools.cycle("⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏"):
            if not self.running:
                break
            sys.stdout.write("\rAI: " + c)
            sys.stdout.flush()
            time.sleep(0.08)

    def stop(self):
        self.running = False
        if self.thread:
            self.thread.join()
        sys.stdout.write("\rAI: ")
        sys.stdout.flush()


# ------------------------------------------------------------
# STREAM
# ------------------------------------------------------------
def chat_stream(model, messages):
    key = load_api_key()
    headers = {
        "Authorization": f"Bearer {key}",
        "Content-Type": "application/json",
        "Accept": "application/x-ndjson"
    }

    payload = {"model": model, "messages": messages, "stream": True}

    r = requests.post(API_CHAT_URL, headers=headers,
                      data=json.dumps(payload), stream=True)
    r.raise_for_status()

    for line in r.iter_lines(decode_unicode=True):
        if not line:
            continue
        try:
            yield json.loads(line)
        except:
            continue


# ------------------------------------------------------------
# INTERACTIVE CHAT
# ------------------------------------------------------------
def interactive():
    print("=== Ollama Cloud Interactive Mode ===")
    print("Fetching model list...\n")

    models = list_models()
    for i, m in enumerate(models):
        print(f"{i+1}. {m['name']}")

    sel = int(input("\nChoose a model: "))
    model = models[sel-1]["name"]

    print(f"\nUsing model: {model}\n")
    print("Type 'exit' to quit.\n")

    history = []

    while True:
        user = input("> ")
        if user == "exit":
            return

        history.append({"role": "user", "content": user})

        spinner = Spinner()
        spinner.start()

        printed_any_token = False
        full_answer = ""

        for chunk in chat_stream(model, history):
            msg = chunk.get("message", {})

            # Skip reasoning tokens
            if msg.get("thinking"):
                continue

            content = msg.get("content")
            if content:
                if not printed_any_token:
                    spinner.stop()
                    print("", end="")
                    printed_any_token = True

                sys.stdout.write(content)
                sys.stdout.flush()
                full_answer += content

            if chunk.get("done"):
                break

        print()
        history.append({"role": "assistant", "content": full_answer})


# ------------------------------------------------------------
# MAIN
# ------------------------------------------------------------
interactive()
